{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Colab environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "username = 'SkoltechAI'\n",
    "repo = 'Recommender-Systems-Intro-Sber-2022'\n",
    "\n",
    "# remove local directory if it already exists\n",
    "if os.path.isdir(repo):\n",
    "    !rm -rf {repo}\n",
    "\n",
    "!git clone https://github.com/{username}/{repo}.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from polara.preprocessing.dataframes import reindex, leave_one_out\n",
    "\n",
    "# navigating to cloned repo directory in Colab\n",
    "%cd {repo}\n",
    "from dataprep import transform_indices, matrix_from_data\n",
    "from evaluation import topn_recommendations, model_evaluate, downvote_seen_items\n",
    "%cd -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to provide `kaggle.json` file after running the cell below! This file contains the necessary information to use Kaggle API under your account.\n",
    "\n",
    "If you don't have this file, navigate to https://www.kaggle.com. Then go to the `Account` tab of your user profile and select `Create API Token`. This will trigger the download of `kaggle.json` to your local machine.\n",
    "\n",
    "Then run the cell below to upload your local `kaggle.json` to the Colab runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for fn in uploaded.keys():\n",
    "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
    "      name=fn, length=len(uploaded[fn])))\n",
    "  \n",
    "# Then move kaggle.json into the folder where the API expects to find it.\n",
    "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competition_name = 'recommender-systems-course-competition-sber2022'\n",
    "competition_data = f'{competition_name}.zip'\n",
    "!kaggle competitions download -c {competition_name}\n",
    "!unzip {competition_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now you should have two files available in the colab: \n",
    "- `train` - a sample of user ratings from the `Movilens 10M` dataset to train models,\n",
    "- `test` - a sample of warm-start users ratings from the same dataset.\n",
    "\n",
    "**Important**: You must NOT use `test` data for training. Only use it for generating recommendations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ = pd.read_csv('train')\n",
    "testset_ = pd.read_csv('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple example with Kaggle submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training, data_index = transform_indices(training_.copy(), 'userid', 'movieid')\n",
    "\n",
    "# we normalize warm-start users index independently of train\n",
    "warm_users_index = pd.Index(testset_['userid'].drop_duplicates(), name='userid') # index for warm-start users\n",
    "testset = reindex(testset_, [warm_users_index, data_index['items']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'users': 'userid',\n",
       " 'items': 'movieid',\n",
       " 'order': 'timestamp',\n",
       " 'n_users': 64680,\n",
       " 'n_items': 9857}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_description = dict(\n",
    "    users = data_index['users'].name,\n",
    "    items = data_index['items'].name,\n",
    "    order = 'timestamp',\n",
    "    n_users = len(data_index['users']),\n",
    "    n_items = len(data_index['items']),\n",
    ")\n",
    "data_description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using simple PureSVD model for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_svd_model(config, data, data_description):\n",
    "    source_matrix = matrix_from_data(data, data_description)\n",
    "    _, s, vt = svds(source_matrix, k=config['rank'], return_singular_vectors='vh')\n",
    "    singular_values = s[::-1]\n",
    "    item_factors = np.ascontiguousarray(vt[::-1, :].T)\n",
    "    return item_factors, singular_values\n",
    "\n",
    "def svd_model_scoring(params, data, data_description):\n",
    "    # data description must contain the correct number of test users\n",
    "    # this will ensure that our scoring matrix will have correct shape\n",
    "    test_data_description = {\n",
    "        **data_description,\n",
    "        'n_users': data[data_description['users']].nunique()\n",
    "    }\n",
    "    test_matrix = matrix_from_data(data, test_data_description)\n",
    "    # generating prediction scores\n",
    "    item_factors, sigma = params\n",
    "    scores = test_matrix.dot(item_factors) @ item_factors.T\n",
    "    return scores\n",
    "\n",
    "def get_svd_recommendations(config, train_data, test_data, data_description, topn=10):\n",
    "    params = build_svd_model(config, train_data, data_description)\n",
    "    scores = svd_model_scoring(params, test_data, data_description)\n",
    "    downvote_seen_items(scores, test_data, data_description)\n",
    "    return topn_recommendations(scores, topn=topn)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_recs = get_svd_recommendations({'rank': 256}, training, testset, data_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_solution(recs_array, test_users, itemidx):\n",
    "    '''\n",
    "    Function to prepare Kaggle submission based on the obtained recommendations.\n",
    "    It converts internal index representation back to original index.\n",
    "    '''\n",
    "    rec_items = itemidx.values.take(recs_array)\n",
    "    useridx = np.broadcast_to(\n",
    "        test_users.values[:, np.newaxis],\n",
    "        (len(test_users), recs_array.shape[1])\n",
    "    )\n",
    "\n",
    "    submission = pd.DataFrame({\n",
    "        test_users.name: useridx.ravel(),\n",
    "        itemidx.name: rec_items.ravel()\n",
    "    })\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = generate_solution(svd_recs, warm_users_index, data_index['items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_file = 'my_first_submission.csv'\n",
    "submission.to_csv(submission_file, index=False)\n",
    "\n",
    "!kaggle competitions submit -c {competition_name} -f {submission_file} -m 'My First Submission'"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3afa3a53b6c5115441aadb460f6d4b1cc743652d4c25bab805986e920f52c789"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('sberrec')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
